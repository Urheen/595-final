{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zX9iRiWbv0Iq"
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Q_BBP2Dv6Jn"
   },
   "source": [
    "### install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ELJhuqBY3FF",
    "outputId": "3ad70b72-fba4-4061-95ca-7e57e70e7441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (4.13.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.2.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (4.61.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (4.8.1)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging>=20.0->transformers) (3.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "\u001B[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xh4dVm1Vv82V"
   },
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fofTPfq-9wcb"
   },
   "outputs": [],
   "source": [
    "import sys, os, copy, json, random, shutil\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, BertForMultipleChoice\n",
    "from transformers import AutoModelForMultipleChoice, AutoTokenizer, TrainingArguments, Trainer\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, RandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiZSUYYblJCc"
   },
   "source": [
    "#### Connect to gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "suSsqFFxlLR-",
    "outputId": "9a9bc3d8-800a-45d6-bd19-9f6b02013a55"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_ye6TAPlYOg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ReEOZUs71wQ"
   },
   "source": [
    "## Config settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "756OW2_yJ1X9"
   },
   "source": [
    "#### Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9UhkNxeWlZcM"
   },
   "outputs": [],
   "source": [
    "# PROJ_DIR = 'gdrive/MyDrive/595finalproj/PIQA/'\n",
    "PROJ_DIR = '/home/ec2-user/SageMaker/test/PIQA/'\n",
    "MAX_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bhuiWWGNl3iE"
   },
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
    "\n",
    "TUNED_LAYERS_NUM = '3' # number of layers that we will update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnXDU-foJ5q_"
   },
   "source": [
    "#### Network params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eyUcBiDXMZEu"
   },
   "outputs": [],
   "source": [
    "args_epoch = 8\n",
    "args_lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "in0DUsxZBXdQ"
   },
   "outputs": [],
   "source": [
    "args_seeds = 728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VD-HFyDHBqdu"
   },
   "outputs": [],
   "source": [
    "args_batch_size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YO-1acXhI103"
   },
   "outputs": [],
   "source": [
    "args_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eSOx3BCZGFui"
   },
   "outputs": [],
   "source": [
    "args_num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fIiM8KqI26u"
   },
   "source": [
    "#### Set up device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNOnjpAlJUYm",
    "outputId": "d612aa13-b8d5-438c-c47b-462fb49945f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "def set_device():\n",
    "  if torch.cuda.is_available():\n",
    "      device = torch.device('cuda:0')\n",
    "  else:\n",
    "      device = torch.device('cpu')\n",
    "  print('using device:', device)\n",
    "  return device\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "device = set_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8tpB-aBI6AK"
   },
   "source": [
    "Set up random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Yf-ckhrSI8ry"
   },
   "outputs": [],
   "source": [
    "def seed_torch(seed=728, is_worker=False):\n",
    "  if not is_worker:\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "  \n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "        \n",
    "def worker_init_fn(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**30 + worker_id\n",
    "    seed_torch(worker_seed, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-p9X7SkJjt5"
   },
   "source": [
    "#### Util settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "n7AMRkGjJlmG"
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(precision=10)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HheuJm_Dv_2S"
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ru5rDLONAvUK"
   },
   "source": [
    "### step 1. Wrap data\n",
    "input: data files \\\\\n",
    "output: required format for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nYvj8bGG6Uzb"
   },
   "outputs": [],
   "source": [
    "def wrap_data(data_name, label_name, max_length_threshold=512, is_test=False):\n",
    "  data_list = []\n",
    "  label_list = []\n",
    "  max_length = -1\n",
    "\n",
    "  with open(PROJ_DIR+data_name, 'r') as f:\n",
    "    datas = list(f)\n",
    "    total_num_sample = len(datas)\n",
    "    print('num of sample: ', total_num_sample)\n",
    "\n",
    "  if not is_test:\n",
    "    with open(PROJ_DIR+label_name, 'r') as f:\n",
    "      labels = list(f)\n",
    "      total_num_label = len(labels)\n",
    "      print('num of label: ', total_num_label)\n",
    "\n",
    "  total_num = total_num_sample\n",
    "\n",
    "  for i in range(total_num):\n",
    "    data = json.loads(datas[i])\n",
    "\n",
    "    if not is_test:\n",
    "      ans = labels[i][:-1]\n",
    "\n",
    "    this_question = data['goal']\n",
    "\n",
    "    this_sol1 = data['sol1']\n",
    "    this_sol2 = data['sol2']\n",
    "\n",
    "\n",
    "    sample = [this_question, this_sol1, this_sol2]\n",
    "\n",
    "    if len(sample[0]) + len(sample[1]) > max_length_threshold:\n",
    "      continue\n",
    "    \n",
    "    if len(sample[0]) + len(sample[2]) > max_length_threshold:\n",
    "      continue \n",
    "\n",
    "    # max_length = max(max_length, len(sample))\n",
    "\n",
    "    if not is_test:\n",
    "#       print(int(ans))\n",
    "      sample.append(int(ans))\n",
    "    else: # if test_dataset, set any fake labels\n",
    "      sample.append(-1)\n",
    "    data_list.append(sample)\n",
    "\n",
    "  return data_list, total_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8ZFvxOh7Xm8",
    "outputId": "7775fdfb-22f9-4dbc-9b80-76fb16be1c11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of sample:  16113\n",
      "num of label:  16113\n",
      "num of sample:  1838\n",
      "num of label:  1838\n",
      "num of sample:  3084\n"
     ]
    }
   ],
   "source": [
    "train_data_list, train_num = wrap_data('train.jsonl', 'train-labels.lst', MAX_LENGTH)\n",
    "val_data_list, val_num = wrap_data('valid.jsonl', 'valid-labels.lst', MAX_LENGTH)\n",
    "test_data_list, test_num = wrap_data('tests.jsonl', 'tests-labels.lst', MAX_LENGTH, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGFlacfGUeo-",
    "outputId": "8bad79b2-87ca-4039-e4b0-06bb18d930c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2070"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve8vbao3kuBL"
   },
   "source": [
    "### step 2. Tokernizer\n",
    "input: required format for the data \\\\\n",
    "output: tokenize input for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "7pkRrJ2A__tR"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UErGq8NBBr5F"
   },
   "outputs": [],
   "source": [
    "train_data_token = []\n",
    "val_data_token = []\n",
    "test_data_token = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "a51a995daec64a4084e927d41c925556",
      "7d9412a705614e7f94446759302211b5",
      "2740236b038a48699ce4c846f418882f",
      "8524420b862e4086a5ff2e825416f8ba",
      "9edc58dc09e14b9085e805614bde47fa",
      "9947462861c641788ff3d2551700057b",
      "43fb4455ec6c4c06a02fcea6547c8f2a",
      "659fec21dea14a858c0e66ac0a9d75ea",
      "609d03fca7dd4ca790ae2f66b8d61838",
      "9c7dd103afd14cb183c71f675326f87c",
      "a90b24c1fa5546cbb92866e5bf4b5a47",
      "a03fc9e623e643efb8b422880253ea32",
      "649c7a548b3644a8bbf7136a106bd793",
      "783c0853a5a441398e88e1dd403737cb",
      "7178653779c840a0af6bf381e9a9490e",
      "6675e028e7cd41bd8c5860aa95dc3d41",
      "d2acd54e0007420fb24c34ea417a45ae",
      "e38070d14810420c84492db589c6d1b3",
      "38d631cff84a4a2d8e48e814c761e0a4",
      "f7bb64338394409b92fd80c6847504a9",
      "4dcb042033eb403b88031d83f2ea0ebe",
      "b846573125fe410fb0ef91ca894df5e8",
      "f4ce30c803444e37a47cd8091adc9786",
      "fc05ec7d7ff94eecbc560fe7d74f2a16",
      "5cd91a4f0c914015ab1620d78066e095",
      "c2ed7d965e2644608187e003830f671b",
      "a1ee31b740924b7a9cfe72c4da86af71",
      "9b32b4bd88ce4a19ba37f95fd7f1a86f",
      "8088754586004f11a419a1aae4259a1f",
      "edf1c2873a234ea8814e353bf3bb01a8",
      "3b24287550a241998e51eda86281d8d4",
      "041ac1dc8f264ae4ad820c6878370543",
      "58364149f49f401a995ed24de6438a57"
     ]
    },
    "id": "Am2tWqmQzYaU",
    "outputId": "5fd72ebd-d004-41df-8d7c-2607f6ff2126"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafe92b105804a008191d6bd5fd56d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a82776d764e41bf9a4fee6209f7a4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 16641, 102, 5672, 13065, 2007, 6173, 9231, 102], [101, 16641, 102, 3926, 1010, 3536, 17643, 2378, 2007, 6173, 9231, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 14113, 2121, 102, 2064, 2022, 2109, 2004, 1037, 11446, 2006, 1037, 2547, 102], [101, 14113, 2121, 102, 2064, 2022, 2109, 2004, 1037, 11446, 2006, 1037, 28407, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 6081, 4524, 102, 2064, 4287, 17910, 102], [101, 6081, 4524, 102, 2064, 4287, 6536, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 1037, 13610, 102, 2064, 2907, 5648, 102], [101, 1037, 13610, 102, 2064, 2907, 6773, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2543, 102, 2064, 14899, 4286, 102], [101, 2543, 102, 2064, 14899, 2300, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 9004, 14405, 102, 2191, 2469, 2017, 5438, 2009, 102], [101, 9004, 14405, 102, 2191, 2009, 5699, 1998, 2025, 5474, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 8153, 102, 2000, 4318, 1037, 2795, 2008, 2001, 2104, 1996, 2712, 102], [101, 8153, 102, 2000, 4318, 1037, 2795, 2008, 2015, 4954, 2104, 1996, 2712, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 5153, 2041, 102, 9200, 2111, 2013, 1996, 5065, 2003, 4658, 102], [101, 5153, 2041, 102, 9200, 2111, 2013, 4774, 3011, 2003, 4658, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 5929, 102, 2064, 2022, 4201, 2006, 1037, 3536, 24000, 2005, 3707, 2075, 102], [101, 5929, 102, 2064, 2022, 4201, 2006, 1037, 2793, 2005, 3707, 2075, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 15488, 14644, 6381, 1029, 102, 10364, 2009, 2035, 2058, 1012, 102], [101, 2129, 2079, 2017, 15488, 14644, 6381, 1029, 102, 14548, 2009, 2035, 2058, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 15019, 102, 2064, 3104, 4597, 102], [101, 15019, 102, 2064, 3104, 14006, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 20619, 102, 4047, 3256, 6949, 23348, 2013, 4053, 102], [101, 20619, 102, 2907, 3256, 6949, 23348, 2000, 2562, 2398, 4010, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 13061, 17910, 102, 2003, 11907, 2084, 1037, 3259, 11179, 102], [101, 13061, 17910, 102, 2064, 2022, 2872, 2104, 1037, 3259, 11179, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 2358, 22134, 1029, 102, 2448, 2066, 2017, 2123, 1005, 1056, 2729, 1012, 102], [101, 2129, 2079, 2017, 2358, 22134, 1029, 102, 3328, 2066, 2017, 2123, 1005, 1056, 2729, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2795, 2327, 102, 2064, 2022, 3714, 2011, 1037, 23526, 102], [101, 2795, 2327, 102, 2064, 2022, 3714, 2011, 1037, 4344, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 15642, 2015, 102, 2064, 23348, 2808, 102], [101, 15642, 2015, 102, 2064, 23348, 3256, 14291, 2015, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 12772, 102, 2064, 26136, 14890, 1037, 9841, 10257, 102], [101, 12772, 102, 2064, 26136, 14890, 1037, 8691, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 10647, 102, 2064, 5672, 1037, 16247, 102], [101, 10647, 102, 2064, 3231, 1996, 6204, 7730, 1997, 1037, 16247, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2907, 1037, 10036, 3614, 1012, 102, 3013, 1037, 2930, 1997, 8288, 11122, 2239, 1012, 102], [101, 2907, 1037, 10036, 3614, 1012, 102, 3013, 1037, 2930, 1997, 8288, 10930, 13687, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 29156, 102, 3084, 23277, 28562, 3711, 102], [101, 29156, 102, 3084, 10424, 11012, 4244, 3711, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2795, 102, 2311, 4275, 9689, 102], [101, 2795, 102, 2311, 1037, 2543, 9689, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 5583, 2619, 1029, 102, 2718, 2068, 2007, 1037, 5583, 1012, 102], [101, 2129, 2079, 2017, 5583, 2619, 1029, 102, 2507, 2068, 1037, 5583, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 5114, 2849, 6740, 1029, 102, 2147, 2041, 2115, 3108, 1012, 102], [101, 2129, 2079, 2017, 5114, 2849, 6740, 1029, 102, 2147, 2041, 2115, 2608, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 14113, 2121, 102, 2064, 2482, 3726, 15708, 3341, 2006, 4853, 102], [101, 14113, 2121, 102, 2064, 2482, 3726, 15708, 15333, 7174, 2860, 21358, 8873, 20156, 2006, 4853, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 4550, 6530, 2452, 16817, 1012, 102, 13387, 2007, 3336, 13387, 2015, 1012, 102], [101, 4550, 6530, 2452, 16817, 1012, 102, 13387, 2007, 8153, 3259, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 18282, 102, 2064, 2433, 2006, 1038, 19738, 2818, 5835, 3254, 1012, 102], [101, 18282, 102, 2064, 2433, 1999, 1996, 6457, 3254, 1012, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 10147, 2290, 2387, 102, 24494, 2015, 3645, 2091, 1012, 102], [101, 10147, 2290, 2387, 102, 24494, 2015, 3765, 2091, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 24532, 12870, 102, 3013, 3930, 2606, 102], [101, 24532, 12870, 102, 3013, 2813, 1997, 2606, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 5909, 102, 2064, 2022, 8828, 2648, 102], [101, 5909, 102, 2064, 2022, 7581, 2012, 2648, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 7198, 14366, 102, 2064, 2907, 1037, 2482, 4089, 1012, 102], [101, 7198, 14366, 102, 2064, 2907, 1037, 9116, 3608, 4089, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2000, 8117, 3401, 1037, 25659, 102, 2224, 1037, 10634, 3829, 5442, 102], [101, 2000, 8117, 3401, 1037, 25659, 102, 2224, 1037, 4629, 3829, 5442, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 4950, 102, 15072, 3465, 2172, 5949, 1999, 1996, 11669, 102], [101, 4950, 102, 15072, 3465, 2172, 2769, 1999, 1996, 11669, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 11848, 8153, 102, 2064, 2022, 3236, 2006, 1037, 26008, 102], [101, 11848, 8153, 102, 2064, 2022, 3236, 2006, 1037, 13675, 28852, 2078, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 22359, 102, 2064, 2022, 2109, 2000, 3713, 2616, 102], [101, 22359, 102, 2064, 2022, 2109, 2000, 4339, 2616, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 6081, 10236, 102, 2064, 3233, 2006, 17910, 102], [101, 6081, 10236, 102, 2064, 10236, 2105, 17910, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 9233, 2953, 102, 2064, 5490, 27020, 2232, 2300, 102], [101, 9233, 2953, 102, 2064, 5490, 27020, 2232, 2300, 10199, 2239, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 7318, 102, 2064, 2191, 1037, 8103, 2005, 1037, 3788, 6293, 102], [101, 7318, 102, 2064, 2191, 1037, 8103, 2005, 1037, 5435, 6865, 2121, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 7438, 1037, 4318, 4451, 1012, 102, 6611, 18781, 4179, 2648, 1997, 4451, 1012, 102], [101, 7438, 1037, 4318, 4451, 1012, 102, 6611, 18781, 4179, 2503, 1997, 4451, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 5660, 1037, 17387, 1029, 102, 14744, 2009, 1999, 1037, 6090, 1012, 102], [101, 2129, 2079, 2017, 5660, 1037, 17387, 1029, 102, 8670, 3489, 2009, 1999, 1996, 17428, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2000, 3013, 1037, 3091, 1997, 26189, 2278, 2000, 2946, 1010, 2017, 2064, 102, 2224, 1037, 12913, 102], [101, 2000, 3013, 1037, 3091, 1997, 26189, 2278, 2000, 2946, 1010, 2017, 2064, 102, 2224, 1037, 2387, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 3259, 11179, 102, 2064, 2022, 2404, 2503, 14829, 102], [101, 3259, 11179, 102, 2064, 2022, 2404, 2503, 2159, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 4487, 13102, 16700, 1997, 2242, 1029, 102, 2404, 2009, 1999, 1037, 3647, 1012, 102], [101, 2129, 2079, 2017, 4487, 13102, 16700, 1997, 2242, 1029, 102, 5466, 2009, 2185, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2398, 102, 2064, 2131, 1037, 9092, 9486, 2039, 102], [101, 2398, 102, 2064, 2131, 19889, 9486, 2039, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 10682, 102, 2064, 2022, 6211, 2084, 1996, 4675, 1012, 102], [101, 10682, 102, 2064, 2022, 2872, 2185, 2013, 1996, 4675, 1012, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 9498, 1037, 2911, 1029, 102, 2404, 2009, 2006, 2300, 1012, 102], [101, 2129, 2079, 2017, 9498, 1037, 2911, 1029, 102, 2404, 2009, 2006, 10869, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 3282, 102, 4288, 19411, 102], [101, 3282, 102, 4288, 9457, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2398, 102, 3013, 2046, 5909, 102], [101, 2398, 102, 3013, 2046, 3384, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2784, 4550, 4157, 23088, 2121, 1012, 102, 26988, 2007, 5785, 1012, 102], [101, 2784, 4550, 4157, 23088, 2121, 1012, 102, 26988, 2007, 13724, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 1037, 8248, 102, 7126, 2562, 10063, 4550, 102], [101, 1037, 8248, 102, 7126, 2562, 2422, 4550, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 3797, 102, 2064, 2022, 6247, 2006, 2132, 2467, 102], [101, 3797, 102, 2064, 2022, 6247, 2006, 2303, 2467, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2214, 3797, 102, 2064, 2022, 6955, 2000, 11573, 2111, 102], [101, 2214, 3797, 102, 2064, 2022, 6955, 2000, 2757, 2111, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 8103, 102, 1055, 2532, 2290, 3589, 9554, 102], [101, 8103, 102, 1055, 2532, 2290, 3392, 9554, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 12341, 102, 2064, 2022, 2109, 2000, 4060, 2039, 15333, 7174, 2125, 1996, 2598, 102], [101, 12341, 102, 2064, 2022, 2109, 2000, 4060, 2039, 4981, 2125, 1996, 2598, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 7499, 2619, 1029, 102, 2360, 2027, 2106, 2009, 1012, 102], [101, 2129, 2079, 2017, 7499, 2619, 1029, 102, 2360, 2017, 2106, 2009, 2005, 2068, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 4840, 2368, 2039, 3052, 1012, 102, 21271, 2006, 1037, 6293, 1997, 21229, 1012, 102], [101, 4840, 2368, 2039, 3052, 1012, 102, 21271, 2006, 1037, 6293, 1997, 13137, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 8691, 2015, 102, 2064, 2022, 16021, 16344, 4904, 8163, 2109, 2006, 11350, 102], [101, 8691, 2015, 102, 2064, 2022, 16021, 16344, 4904, 8163, 2109, 1999, 2686, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2048, 19896, 102, 4175, 2005, 2062, 2084, 2028, 9292, 102], [101, 2048, 19896, 102, 4175, 2005, 2062, 2084, 2751, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 7815, 102, 2064, 4550, 18282, 102], [101, 7815, 102, 2064, 4550, 1037, 2482, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 10810, 102, 4324, 2439, 2477, 102], [101, 10810, 102, 4324, 2235, 2477, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 16641, 102, 2064, 2022, 1037, 3233, 2005, 1037, 6546, 18781, 102], [101, 16641, 102, 2064, 2022, 1037, 3233, 2005, 1037, 10818, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 6557, 3608, 102, 2064, 4550, 10647, 2007, 2566, 28479, 102], [101, 6557, 3608, 102, 2064, 2433, 10647, 4089, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 22863, 102, 2003, 2109, 2000, 2022, 3760, 2084, 5800, 102], [101, 22863, 102, 2003, 2109, 2000, 2022, 3760, 2084, 11300, 3388, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 25813, 2064, 102, 4287, 2336, 2000, 1996, 3573, 102], [101, 25813, 2064, 102, 4287, 7824, 2000, 1996, 3573, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 19622, 102, 2064, 2022, 2404, 2046, 4234, 26412, 102], [101, 19622, 102, 2064, 2022, 2404, 2046, 4234, 15664, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 13675, 28852, 2078, 102, 2064, 3609, 1996, 3681, 19957, 102], [101, 13675, 28852, 2078, 102, 2064, 3609, 1996, 3259, 19957, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 6085, 102, 2064, 3013, 1037, 3797, 102], [101, 6085, 102, 2064, 3013, 1037, 2543, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 4605, 102, 2064, 3573, 11350, 102], [101, 4605, 102, 2064, 3573, 6007, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 3145, 102, 2064, 2022, 5023, 2503, 1037, 2795, 23095, 102], [101, 3145, 102, 2064, 2022, 5023, 2503, 1037, 1059, 24158, 2243, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2330, 15723, 102, 2191, 2469, 2017, 2963, 1996, 11562, 102], [101, 2330, 15723, 102, 11112, 3953, 1998, 9792, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2191, 1037, 2067, 1997, 4540, 4892, 102, 2202, 1037, 2235, 3538, 102], [101, 2191, 1037, 2067, 1997, 4540, 4892, 102, 2224, 1037, 14745, 22505, 2099, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 11848, 8153, 102, 2064, 11969, 3336, 9898, 1012, 102], [101, 11848, 8153, 102, 2064, 2907, 3336, 9898, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 13017, 4060, 4244, 102, 6986, 4318, 2077, 14744, 2075, 102], [101, 13017, 4060, 4244, 102, 4897, 1999, 13724, 1998, 2139, 2361, 14744, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2000, 2330, 1037, 5843, 17800, 1029, 102, 7987, 5243, 6711, 1996, 5843, 102], [101, 2129, 2000, 2330, 1037, 5843, 17800, 1029, 102, 2224, 1037, 3145, 2000, 2330, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 6366, 5472, 2013, 2519, 1012, 102, 14548, 2007, 3336, 3514, 1012, 102], [101, 6366, 5472, 2013, 2519, 1012, 102, 14548, 2007, 3336, 9898, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 7438, 6740, 13675, 16613, 1012, 102, 4392, 4060, 2571, 10869, 1012, 102], [101, 7438, 6740, 13675, 16613, 1012, 102, 4392, 2665, 9724, 10869, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 24532, 12870, 102, 2064, 5468, 1037, 7786, 102], [101, 24532, 12870, 102, 2064, 7358, 2083, 1037, 7786, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 24635, 102, 2064, 2022, 2081, 2013, 13065, 2894, 102], [101, 24635, 102, 2064, 4372, 8017, 3351, 13065, 2043, 5507, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 2928, 2242, 1029, 102, 2191, 2009, 1996, 2168, 1012, 102], [101, 2129, 2079, 2017, 2928, 2242, 1029, 102, 2191, 2009, 2367, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 6823, 102, 2064, 2562, 1037, 3332, 2701, 102], [101, 6823, 102, 2064, 2562, 1037, 3482, 2701, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 24532, 12870, 102, 2064, 3913, 2006, 1996, 2795, 23095, 102], [101, 24532, 12870, 102, 2064, 10671, 1037, 2795, 23095, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 5929, 102, 2064, 2022, 2701, 2362, 2011, 9090, 12528, 102], [101, 5929, 102, 2064, 2022, 2701, 2362, 2011, 3482, 16343, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 14113, 2121, 102, 2064, 4906, 2503, 1037, 14187, 2121, 12528, 102], [101, 14113, 2121, 102, 2064, 4906, 2503, 1037, 8070, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2000, 2292, 2175, 1997, 5346, 1029, 102, 5390, 2068, 2041, 102], [101, 2129, 2000, 2292, 2175, 1997, 5346, 1029, 102, 8568, 2068, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 4605, 102, 1037, 2064, 2022, 2109, 2000, 4521, 20943, 102], [101, 4605, 102, 1037, 2064, 2022, 2109, 2000, 2831, 2000, 20943, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 10810, 102, 2064, 2025, 2717, 2006, 1037, 20619, 102], [101, 10810, 102, 2064, 2025, 2717, 2006, 1037, 2452, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 3538, 1997, 27201, 6090, 3723, 15006, 2063, 102, 3104, 2227, 102], [101, 3538, 1997, 27201, 6090, 3723, 15006, 2063, 102, 3104, 2311, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 12668, 102, 2064, 26202, 15333, 7174, 102], [101, 12668, 102, 2064, 26202, 6064, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 10768, 28228, 28863, 102, 2064, 2022, 2109, 2005, 3652, 4264, 102], [101, 10768, 28228, 28863, 102, 2064, 2022, 2109, 2005, 3652, 5749, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2398, 102, 2064, 3543, 2300, 102], [101, 2398, 102, 2064, 3543, 2543, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 8164, 102, 2064, 2022, 2404, 2105, 1037, 2813, 102], [101, 8164, 102, 2064, 2022, 2404, 2105, 1037, 14809, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 23528, 102, 2064, 4550, 2039, 2300, 14437, 2015, 102], [101, 23528, 102, 2064, 4550, 2039, 4318, 4157, 2598, 14437, 2015, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2000, 2562, 2115, 2773, 1029, 102, 2079, 2054, 2017, 2360, 2017, 2097, 102], [101, 2000, 2562, 2115, 2773, 1029, 102, 2079, 2054, 2017, 2360, 2017, 2180, 1005, 1056, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 2224, 1037, 2909, 2072, 10293, 1029, 102, 2907, 2091, 2006, 2009, 1012, 102], [101, 2129, 2079, 2017, 2224, 1037, 2909, 2072, 10293, 1029, 102, 11112, 2006, 2009, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 16360, 2884, 10029, 102, 5587, 1037, 2261, 102], [101, 16360, 2884, 10029, 102, 5587, 10647, 2000, 1037, 3221, 1997, 2300, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 1037, 5442, 102, 2064, 4651, 16575, 2013, 1037, 3221, 1012, 102], [101, 1037, 5442, 102, 2064, 4651, 6381, 2013, 1037, 3221, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 12115, 102, 22505, 2015, 14745, 6017, 102], [101, 12115, 102, 2612, 1997, 14745, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 3256, 6949, 23348, 102, 2064, 14804, 2571, 11350, 102], [101, 3256, 6949, 23348, 102, 2064, 14804, 2571, 1037, 7975, 7388, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 3628, 102, 3073, 5014, 2005, 2111, 102], [101, 3628, 102, 3073, 5014, 2005, 4176, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 3256, 4060, 102, 2003, 2109, 2000, 6402, 2039, 1037, 15082, 102], [101, 3256, 4060, 102, 2003, 4788, 2012, 6276, 10154, 2015, 2084, 1037, 15082, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 1010, 1037, 5442, 102, 2064, 6033, 1037, 8903, 3608, 102], [101, 1010, 1037, 5442, 102, 2064, 6033, 1037, 7720, 3608, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 7551, 2007, 2242, 1029, 102, 2224, 2009, 1012, 102], [101, 2129, 2079, 2017, 7551, 2007, 2242, 1029, 102, 3231, 2009, 2041, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 15740, 2015, 102, 2064, 4666, 16521, 102], [101, 15740, 2015, 102, 2064, 4666, 11225, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 12115, 102, 2064, 4009, 2006, 1037, 2304, 6277, 102], [101, 12115, 102, 2064, 4009, 2006, 1037, 2227, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 23951, 1029, 102, 2265, 2115, 6650, 1012, 102], [101, 2129, 2079, 2017, 23951, 1029, 102, 3913, 2091, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2000, 6073, 2115, 2132, 1029, 102, 2693, 2009, 2039, 1998, 2091, 102], [101, 2000, 6073, 2115, 2132, 1029, 102, 2693, 2009, 2217, 2000, 2217, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 14366, 102, 2003, 5044, 2066, 15270, 11563, 102], [101, 14366, 102, 2003, 2109, 2066, 15270, 11563, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2915, 3221, 102, 2064, 2828, 2006, 1037, 13855, 102], [101, 2915, 3221, 102, 2064, 4133, 2006, 1037, 13855, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 7518, 2316, 102, 3104, 4641, 102], [101, 7518, 2316, 102, 3104, 17860, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 6670, 3388, 102, 2064, 3338, 14187, 2121, 12528, 2125, 3435, 3678, 102], [101, 6670, 3388, 102, 2064, 29198, 14187, 2121, 12528, 2125, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 18484, 102, 2064, 2907, 18484, 102], [101, 18484, 102, 2064, 2907, 25636, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 8248, 6497, 2125, 8407, 1012, 102, 2224, 11868, 18623, 2000, 18087, 1012, 102], [101, 8248, 6497, 2125, 8407, 1012, 102, 2224, 11394, 13109, 15094, 2000, 18087, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 15114, 102, 2064, 2022, 3013, 2011, 16596, 9363, 2869, 2007, 7496, 102], [101, 15114, 102, 2064, 2022, 3013, 2011, 1037, 5442, 2007, 7496, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 3282, 102, 2064, 6271, 2039, 2833, 13151, 102], [101, 3282, 102, 2064, 6271, 2039, 21719, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 16215, 5714, 3468, 102, 2064, 4906, 2006, 1037, 15723, 102], [101, 16215, 5714, 3468, 102, 2064, 4906, 2006, 1037, 13675, 28852, 2078, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 7318, 27259, 102, 2064, 2907, 9502, 3111, 1012, 102], [101, 7318, 27259, 102, 2064, 2907, 10268, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 12121, 102, 2064, 2022, 2109, 2000, 2240, 17387, 9543, 2015, 102], [101, 12121, 102, 2064, 2022, 2109, 2000, 2240, 6471, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 7345, 102, 24758, 2160, 102], [101, 7345, 102, 24758, 15642, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 13137, 102, 2064, 2022, 5507, 2005, 2543, 2000, 2994, 4010, 102], [101, 13137, 102, 2064, 2022, 5507, 2005, 2300, 2000, 2994, 4010, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 5245, 9231, 102, 2000, 7367, 2860, 1998, 2273, 2094, 10210, 25808, 102], [101, 5245, 9231, 102, 2000, 6865, 10210, 25808, 2006, 8513, 6277, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2000, 18554, 27158, 1012, 102, 16510, 27158, 2046, 13610, 2440, 1997, 18554, 1012, 102], [101, 2129, 2000, 18554, 27158, 1012, 102, 16510, 27158, 2046, 25102, 2440, 1997, 18554, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2723, 102, 2064, 2907, 1037, 6081, 4524, 2006, 2327, 1997, 2009, 102], [101, 2723, 102, 2064, 5342, 1037, 6081, 4524, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 17736, 102, 2064, 2022, 2109, 2000, 3965, 2557, 4742, 102], [101, 17736, 102, 2064, 2022, 2109, 2000, 3796, 2557, 4742, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 20228, 10136, 102, 2064, 8815, 3384, 1999, 2431, 102], [101, 20228, 10136, 102, 2064, 8815, 5929, 1999, 2431, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 7877, 102, 3499, 2111, 2000, 7200, 2043, 6247, 102], [101, 7877, 102, 3499, 2111, 2000, 2156, 2043, 6247, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 6081, 10236, 102, 2064, 2562, 14904, 4840, 102], [101, 6081, 10236, 102, 2064, 2562, 5909, 4840, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 4440, 2006, 2242, 1029, 102, 2471, 2991, 2058, 2009, 1012, 102], [101, 2129, 2079, 2017, 4440, 2006, 2242, 1029, 102, 5376, 2058, 2009, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 17768, 102, 4550, 2015, 7390, 102], [101, 17768, 102, 4550, 2015, 4253, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2191, 5057, 2482, 2452, 9111, 1012, 102, 2173, 2452, 1999, 6045, 1012, 102], [101, 2191, 5057, 2482, 2452, 9111, 1012, 102, 2173, 2452, 1999, 10818, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2677, 102, 2064, 3422, 2678, 8333, 1012, 102], [101, 2677, 102, 2064, 26927, 17258, 2063, 5746, 2005, 1037, 2678, 8570, 1012, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 3233, 102, 2064, 2490, 1037, 2547, 102], [101, 3233, 102, 2064, 2490, 11350, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 1037, 13183, 102, 26929, 25659, 2015, 102], [101, 1037, 13183, 102, 26929, 1037, 2878, 10369, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 11220, 102, 2064, 4897, 2058, 1037, 10535, 102], [101, 11220, 102, 2064, 4897, 2058, 1037, 2338, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 6670, 3388, 102, 2064, 2373, 16247, 102], [101, 6670, 3388, 102, 2064, 14899, 2058, 1037, 16247, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 6045, 102, 2064, 2022, 7429, 2007, 12944, 2121, 102], [101, 6045, 102, 2064, 2022, 7429, 2007, 5153, 2041, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 3684, 2121, 102, 12959, 4049, 4089, 102], [101, 3684, 2121, 102, 12959, 16125, 4089, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 13109, 15094, 102, 2064, 2022, 24009, 2000, 1037, 2813, 2011, 12115, 102], [101, 13109, 15094, 102, 2064, 2022, 24009, 2000, 1037, 2813, 2011, 9231, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 5509, 102, 13945, 17321, 102], [101, 5509, 102, 13945, 5800, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 8070, 102, 2064, 2707, 8769, 2007, 1037, 1059, 24158, 2243, 102], [101, 8070, 102, 2003, 8250, 2007, 1037, 1059, 24158, 2243, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 4540, 4892, 2067, 102, 2064, 3573, 9543, 17910, 2503, 102], [101, 4540, 4892, 2067, 102, 2064, 9267, 9543, 17910, 2000, 2191, 4714, 4920, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2300, 102, 2064, 19549, 1037, 2158, 102], [101, 2300, 102, 2064, 19549, 1037, 3869, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 13227, 102, 2064, 8339, 2422, 2013, 4768, 102], [101, 13227, 102, 2064, 8339, 2422, 2013, 1996, 3103, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 15019, 102, 7906, 1996, 3103, 4010, 102], [101, 15019, 102, 7906, 6077, 4010, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 10682, 102, 7719, 2723, 102], [101, 10682, 102, 7719, 19747, 3482, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2300, 102, 8542, 2006, 4950, 2003, 15011, 102], [101, 2300, 102, 8542, 2006, 2048, 19896, 2003, 15011, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 3256, 4060, 102, 2064, 26202, 2083, 3384, 8177, 102], [101, 3256, 4060, 102, 2064, 26202, 2083, 8416, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 3103, 14479, 12053, 102, 3084, 10424, 11012, 4244, 3711, 102], [101, 3103, 14479, 12053, 102, 3084, 13560, 3711, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 5291, 9231, 102, 5164, 7318, 102], [101, 5291, 9231, 102, 10236, 7318, 15981, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 26997, 102, 2064, 6865, 2039, 14921, 2006, 1996, 2813, 102], [101, 26997, 102, 2064, 6865, 2039, 10366, 5265, 2006, 1996, 2813, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 13061, 17910, 102, 2003, 6428, 2084, 1037, 3259, 11179, 1012, 102], [101, 13061, 17910, 102, 2064, 2025, 2022, 1037, 2204, 3259, 11179, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 9485, 9841, 102, 2064, 2022, 2109, 2000, 3573, 22746, 6067, 102], [101, 9485, 9841, 102, 2064, 2022, 2109, 2000, 3573, 27997, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 5259, 102, 2064, 2022, 3714, 2011, 1037, 5318, 2065, 6908, 102], [101, 5259, 102, 2064, 2022, 3714, 2011, 1037, 3797, 2065, 6908, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2019, 12946, 102, 2064, 15132, 1037, 7053, 2330, 102], [101, 2019, 12946, 102, 2064, 15132, 2019, 6207, 3392, 2330, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 3336, 9898, 102, 2064, 2022, 8342, 2039, 2011, 3256, 6949, 23348, 102], [101, 3336, 9898, 102, 2064, 2022, 8342, 2039, 2011, 20619, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2128, 20192, 2102, 5785, 102, 2061, 4817, 5785, 1999, 2300, 1998, 1998, 18302, 1012, 102], [101, 2128, 20192, 2102, 5785, 102, 2173, 3256, 14291, 2006, 5785, 1998, 18302, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 3712, 3213, 13297, 102, 7009, 2006, 1996, 2598, 102], [101, 3712, 3213, 13297, 102, 7009, 2006, 2250, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 2033, 11057, 28632, 2242, 1029, 102, 4638, 2009, 1005, 1055, 3091, 1012, 102], [101, 2129, 2079, 2017, 2033, 11057, 28632, 2242, 1029, 102, 4638, 2049, 3609, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 7345, 102, 2064, 8595, 1037, 2813, 2302, 2172, 3255, 102], [101, 7345, 102, 2064, 8595, 1037, 10005, 2302, 2172, 3255, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 24494, 21354, 2015, 102, 2064, 11969, 1037, 5259, 102], [101, 24494, 21354, 2015, 102, 2064, 10188, 1037, 5259, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 4344, 25464, 102, 2064, 2022, 3714, 2006, 1996, 3341, 1997, 1037, 8026, 102], [101, 4344, 25464, 102, 2064, 5342, 1037, 8026, 8026, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 5430, 102, 7906, 1996, 22177, 4838, 102], [101, 5430, 102, 7906, 1996, 3137, 4838, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 14095, 102, 14612, 27518, 4550, 2135, 102], [101, 14095, 102, 14612, 2398, 4550, 2135, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 11661, 102, 2064, 28667, 2100, 14321, 9543, 17910, 102], [101, 11661, 102, 2064, 5383, 9543, 17910, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 14187, 2121, 12528, 102, 9378, 14829, 102], [101, 14187, 2121, 12528, 102, 2562, 14829, 2039, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2000, 2139, 20110, 2619, 1029, 102, 2191, 2068, 4854, 102], [101, 2000, 2139, 20110, 2619, 1029, 102, 2191, 2068, 6517, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 10178, 2121, 102, 2064, 2175, 1999, 15270, 11563, 102], [101, 10178, 2121, 102, 2064, 2175, 1999, 4060, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 8768, 102, 2064, 13387, 9841, 10257, 102], [101, 8768, 102, 2064, 13387, 2387, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 5610, 102, 2064, 2928, 3259, 2007, 3609, 102], [101, 5610, 102, 2064, 2928, 2250, 2007, 3609, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 25850, 24667, 102, 4550, 2015, 2606, 2013, 6900, 102], [101, 25850, 24667, 102, 4550, 2015, 4253, 2013, 6900, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 22737, 3064, 5442, 102, 2064, 3013, 3221, 102], [101, 22737, 3064, 5442, 102, 2064, 3013, 1037, 2064, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 2079, 2242, 2855, 1029, 102, 2175, 3435, 1012, 102], [101, 2129, 2079, 2017, 2079, 2242, 2855, 1029, 102, 2175, 4030, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 28667, 4179, 1029, 102, 4133, 2067, 1012, 102], [101, 2129, 2079, 2017, 28667, 4179, 1029, 102, 4133, 2830, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 9587, 2361, 102, 2038, 1037, 6085, 102], [101, 9587, 2361, 102, 2038, 1037, 2146, 5047, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 7374, 2619, 1029, 102, 2131, 2068, 3201, 1012, 102], [101, 2129, 2079, 2017, 7374, 2619, 1029, 102, 2425, 2068, 2054, 2000, 2079, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2980, 11687, 102, 2064, 2202, 2185, 19029, 2855, 102], [101, 2980, 11687, 102, 2064, 2202, 2185, 4308, 12336, 2855, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 18282, 102, 2064, 3104, 1037, 24596, 1012, 102], [101, 18282, 102, 2003, 2062, 6179, 2084, 1037, 24596, 1012, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 13137, 102, 2064, 16130, 22177, 2005, 4596, 102], [101, 13137, 102, 2064, 16130, 2833, 2005, 4596, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2000, 8815, 10466, 1999, 7318, 102, 2224, 12201, 4451, 20228, 10136, 102], [101, 2000, 8815, 10466, 1999, 7318, 102, 2224, 12201, 4451, 1056, 28394, 16750, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 11848, 102, 10861, 12680, 2785, 2571, 102], [101, 11848, 102, 10861, 12680, 5785, 16546, 2099, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2104, 2849, 102, 2064, 4287, 5167, 2300, 10199, 2239, 102], [101, 2104, 2849, 102, 2064, 4287, 5167, 2338, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 19896, 102, 2024, 5044, 2066, 15390, 2545, 102], [101, 19896, 102, 2024, 5044, 2066, 10974, 29278, 2243, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 9090, 12528, 102, 2064, 10939, 4981, 102], [101, 9090, 12528, 102, 2064, 10939, 7824, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 25946, 102, 2064, 3573, 2374, 2015, 102], [101, 25946, 102, 2064, 3573, 21066, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 8962, 1998, 11876, 102, 2064, 5660, 2833, 2006, 1996, 2598, 1012, 102], [101, 8962, 1998, 11876, 102, 2064, 5660, 2833, 2006, 1996, 16247, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 11868, 19707, 2618, 102, 2064, 18282, 11342, 102], [101, 11868, 19707, 2618, 102, 2064, 18282, 2606, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 6090, 102, 2064, 5660, 11611, 102], [101, 6090, 102, 2064, 5660, 23126, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 6381, 102, 2644, 8769, 102], [101, 6381, 102, 2644, 9451, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 2663, 1037, 5981, 1029, 102, 7475, 25493, 1012, 102], [101, 2129, 2079, 2017, 2663, 1037, 5981, 1029, 102, 2031, 1996, 2190, 2553, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 16833, 102, 2064, 4089, 2022, 3631, 2007, 9543, 17910, 102], [101, 16833, 102, 2064, 4089, 2022, 3631, 2007, 7345, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 2330, 1037, 22939, 4842, 1029, 102, 4139, 1996, 2048, 4515, 4237, 1012, 102], [101, 2129, 2079, 2017, 2330, 1037, 22939, 4842, 1029, 102, 3013, 1996, 2048, 4515, 4237, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2000, 2079, 1037, 16030, 3105, 1029, 102, 2202, 2115, 2051, 102], [101, 2000, 2079, 1037, 16030, 3105, 1029, 102, 2079, 2009, 2855, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 24582, 2075, 102, 2064, 2022, 2109, 2000, 29460, 4377, 102], [101, 24582, 2075, 102, 2064, 2022, 2109, 2000, 29460, 9850, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 6173, 9231, 102, 2064, 9267, 12201, 4089, 102], [101, 6173, 9231, 102, 2907, 2606, 2612, 1997, 12201, 2005, 3808, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 1999, 10258, 3686, 1037, 12824, 1029, 102, 2292, 1996, 2250, 2041, 1012, 102], [101, 2129, 2079, 2017, 1999, 10258, 3686, 1037, 12824, 1029, 102, 6039, 2009, 2007, 2250, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 9090, 12528, 102, 2064, 2022, 3714, 2011, 1037, 2604, 102], [101, 9090, 12528, 102, 2064, 2022, 3714, 2011, 1037, 9378, 8416, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 4030, 16546, 2099, 102, 2064, 14899, 12136, 102], [101, 4030, 16546, 2099, 102, 2064, 14899, 6967, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 13675, 28852, 2078, 102, 2064, 3609, 1037, 3259, 10257, 4897, 2665, 102], [101, 13675, 28852, 2078, 102, 2064, 3609, 1037, 5835, 2665, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 3329, 102, 2064, 4929, 1037, 28407, 102], [101, 3329, 102, 2064, 4929, 1037, 2061, 19908, 3217, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 9138, 102, 7641, 2227, 102], [101, 9138, 102, 7641, 2250, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 1053, 1011, 5955, 102, 4550, 2015, 5551, 5251, 1012, 102], [101, 1053, 1011, 5955, 102, 4550, 2015, 4540, 5033, 5251, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 8808, 8416, 102, 4324, 3329, 102], [101, 8808, 8416, 102, 4324, 11868, 19707, 2618, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 9378, 23095, 102, 2064, 13387, 2185, 18499, 2229, 2006, 1996, 3096, 102], [101, 9378, 23095, 102, 2064, 13387, 2185, 7518, 2006, 1996, 3096, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 1059, 24158, 2243, 102, 2064, 4666, 2039, 24665, 11431, 2100, 102], [101, 1059, 24158, 2243, 102, 2064, 4666, 2039, 6386, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 8768, 102, 2064, 3104, 1037, 10682, 2013, 6900, 102], [101, 8768, 102, 2064, 2191, 1037, 10682, 8841, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 21290, 102, 2064, 3013, 4950, 4089, 102], [101, 21290, 102, 2064, 2022, 13802, 2011, 4950, 2006, 3036, 8080, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 3536, 102, 2064, 2022, 7844, 2046, 1037, 9292, 102], [101, 3536, 102, 2064, 2482, 3726, 1037, 9292, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 3093, 102, 2064, 2022, 5058, 1999, 9543, 17910, 102], [101, 3093, 102, 2064, 2022, 5058, 1999, 12668, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 11848, 8153, 102, 2064, 4550, 2606, 102], [101, 11848, 8153, 102, 2064, 4550, 1996, 7752, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 3066, 2007, 19029, 1029, 102, 4521, 2062, 1012, 102], [101, 2129, 2079, 2017, 3066, 2007, 19029, 1029, 102, 5466, 2039, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 10810, 102, 2064, 4372, 20464, 9232, 1037, 3808, 9231, 102], [101, 10810, 102, 2064, 4372, 20464, 9232, 1037, 15876, 2721, 27669, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 9526, 1037, 14978, 2007, 1037, 4392, 1012, 102, 24702, 2070, 14580, 5572, 1012, 102], [101, 9526, 1037, 14978, 2007, 1037, 4392, 1012, 102, 24702, 2070, 12849, 4747, 1011, 4681, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 18856, 16613, 102, 2064, 2022, 2109, 2066, 1037, 12115, 102], [101, 18856, 16613, 102, 2064, 2907, 1037, 12115, 12115, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 2655, 1996, 11865, 13213, 102, 13764, 19989, 102], [101, 2129, 2079, 2017, 2655, 1996, 11865, 13213, 102, 13764, 11865, 13213, 2104, 10402, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 20619, 102, 2064, 16888, 6381, 2066, 2064, 102], [101, 20619, 102, 2064, 16888, 6381, 2066, 14829, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2000, 4317, 2368, 1037, 8150, 102, 5587, 9781, 2732, 2818, 102], [101, 2000, 4317, 2368, 1037, 8150, 102, 5587, 9781, 23353, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 18330, 2015, 102, 7659, 25840, 4550, 2135, 102], [101, 18330, 2015, 102, 7659, 8351, 4550, 2135, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 3042, 102, 2064, 7532, 2111, 2007, 2060, 2111, 102], [101, 3042, 102, 2064, 7532, 8870, 2007, 2060, 2111, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2129, 2079, 2017, 18168, 12474, 1996, 3606, 1029, 102, 2123, 1005, 1056, 2425, 2009, 1012, 102], [101, 2129, 2079, 2017, 18168, 12474, 1996, 3606, 1029, 102, 2360, 2009, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 15545, 102, 22164, 5633, 102], [101, 15545, 102, 22164, 18245, 1012, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 22147, 2078, 1037, 14745, 102, 3013, 19754, 2135, 102], [101, 22147, 2078, 1037, 14745, 102, 2224, 1037, 5442, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 7815, 102, 2064, 4906, 1999, 10810, 102], [101, 7815, 102, 2064, 4906, 1999, 21522, 7123, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 4013, 6494, 16761, 102, 2064, 17079, 17357, 11829, 102], [101, 4013, 6494, 16761, 102, 2064, 17079, 16240, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 24596, 102, 4550, 2015, 2039, 5749, 2065, 13439, 102], [101, 24596, 102, 4550, 2015, 2039, 2668, 2065, 13439, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 16716, 102, 16263, 6240, 2013, 27594, 2075, 102], [101, 16716, 102, 16263, 2444, 4264, 2013, 27594, 2075, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 7151, 102, 2064, 3637, 2006, 1037, 11224, 23663, 2099, 102], [101, 7151, 102, 2064, 4392, 1037, 11224, 23663, 2099, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 19622, 102, 2064, 2907, 4253, 6865, 2545, 2007, 4253, 2006, 102], [101, 19622, 102, 2064, 2907, 3259, 14421, 2007, 4253, 2006, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2980, 10210, 3215, 102, 2064, 2562, 4010, 2398, 1999, 1996, 4586, 102], [101, 2980, 10210, 3215, 102, 2064, 2562, 4010, 15190, 2015, 1999, 1996, 4586, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 13724, 102, 2064, 2191, 23126, 2043, 4954, 102], [101, 13724, 102, 2064, 2191, 6081, 2043, 4954, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 14704, 2099, 102, 2064, 14021, 5596, 3259, 2046, 9017, 102], [101, 14704, 2099, 102, 2064, 14021, 5596, 5749, 2046, 9017, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 18785, 2099, 102, 2064, 24234, 2330, 25730, 102], [101, 18785, 2099, 102, 2064, 24234, 2330, 2924, 11632, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 4654, 3540, 22879, 2953, 102, 10667, 11564, 102], [101, 4654, 3540, 22879, 2953, 102, 10667, 11297, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 1037, 19075, 102, 2039, 20192, 6961, 12419, 2791, 18228, 102], [101, 1037, 19075, 102, 2039, 20192, 6961, 3864, 18228, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 7381, 102, 2064, 2022, 2109, 2000, 3573, 3506, 1999, 102], [101, 7381, 102, 2064, 2022, 2109, 2000, 3573, 13310, 1999, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 2808, 102, 2016, 26832, 2006, 15871, 1997, 3332, 102], [101, 2808, 102, 2016, 26832, 2006, 18283, 1997, 3332, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 1037, 11142, 102, 2064, 2907, 1037, 2338, 102], [101, 1037, 11142, 102, 2064, 2907, 6501, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 9078, 5524, 102, 9268, 7279, 6017, 9689, 102], [101, 9078, 5524, 102, 9268, 2566, 28479, 9689, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2030, 18442, 3372, 102, 2064, 29460, 3392, 102], [101, 2030, 18442, 3372, 102, 2064, 29460, 4624, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 11661, 102, 2064, 3573, 9543, 17910, 102], [101, 11661, 102, 2064, 3013, 9543, 17910, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 2932, 102, 2064, 2022, 9868, 2065, 2027, 2131, 4954, 2011, 1037, 9587, 2361, 102], [101, 2932, 102, 2064, 2022, 9868, 2065, 2027, 2131, 4954, 2011, 1037, 15723, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n",
      "{'input_ids': [[101, 1037, 25742, 102, 2064, 4550, 1037, 2482, 7919, 102], [101, 1037, 25742, 102, 2064, 4550, 4091, 7919, 102]], 'token_type_ids': [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4109e8b8944d15bced64cd8b1b9d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for sample in tqdm(train_data_list):\n",
    "  prompt, choice0, choice1, labels = sample[0], sample[1], sample[2], sample[3]\n",
    "  encoding = tokenizer([prompt, prompt], [choice0, choice1], truncation=True)\n",
    "  encoding['labels'] = labels\n",
    "  train_data_token.append(encoding)\n",
    "\n",
    "for sample in tqdm(val_data_list):\n",
    "  prompt, choice0, choice1, labels = sample[0], sample[1], sample[2], sample[3]\n",
    "  encoding = tokenizer([prompt, prompt], [choice0, choice1], truncation=True)\n",
    "  encoding['labels'] = labels\n",
    "  print(encoding)\n",
    "  val_data_token.append(encoding)\n",
    "\n",
    "for sample in tqdm(test_data_list):\n",
    "  prompt, choice0, choice1, labels = sample[0], sample[1], sample[2], sample[3]\n",
    "  encoding = tokenizer([prompt, prompt], [choice0, choice1], truncation=True)\n",
    "  encoding['labels'] = labels\n",
    "  test_data_token.append(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 16641, 102, 5672, 13065, 2007, 6173, 9231, 102], [101, 16641, 102, 3926, 1010, 3536, 17643, 2378, 2007, 6173, 9231, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n"
     ]
    }
   ],
   "source": [
    "print(val_data_token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "az8nOKQ6zuH0",
    "outputId": "e2daf2e7-1b92-4d41-c893-cdaf193090dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2070, 239, 399)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_token), len(val_data_token), len(test_data_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rub2lFpMBMFL"
   },
   "source": [
    "### step 3. Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "datasets['train'] = train_data_token\n",
    "datasets['validation'] = val_data_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        for idx, _ in enumerate(features):\n",
    "            features[idx]['labels'] = labels[idx]\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 16641, 102, 5672, 13065, 2007, 6173, 9231, 102], [101, 16641, 102, 3926, 1010, 3536, 17643, 2378, 2007, 6173, 9231, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n",
      "{'input_ids': [[101, 16641, 102, 5672, 13065, 2007, 6173, 9231, 102], [101, 16641, 102, 3926, 1010, 3536, 17643, 2378, 2007, 6173, 9231, 102]], 'token_type_ids': [[0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': 1}\n"
     ]
    }
   ],
   "source": [
    "accepted_keys = [\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"]\n",
    "features = [{k: v for k, v in val_data_token[i].items() if k in accepted_keys} for i in range(10)]\n",
    "print(features[0])\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)\n",
    "print(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 15])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wccQzF7BT6Y"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJENDWO1wEky"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMultipleChoice.from_pretrained(PRE_TRAINED_MODEL_NAME).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ziyan-595finalproj'\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-piqa\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=args_lr,\n",
    "    per_device_train_batch_size=args_batch_size,\n",
    "    per_device_eval_batch_size=args_batch_size,\n",
    "    num_train_epochs=args_epoch,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_strategy='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJyrs4FlAqq"
   },
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oGYCVIGTk_z0",
    "outputId": "3c5b6cda-932d-43d5-bb96-64b0fbd11747"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'module.classifier.weight', 'module.classifier.bias']\n"
     ]
    }
   ],
   "source": [
    "nonfreeze_layers = []\n",
    "\n",
    "for name, _ in model.named_parameters():\n",
    "#   print(name)\n",
    "  if '.' + TUNED_LAYERS_NUM + '.' in name:\n",
    "    break\n",
    "  nonfreeze_layers.append(name)\n",
    "\n",
    "nonfreeze_layers.append(\"module.classifier.weight\")\n",
    "nonfreeze_layers.append(\"module.classifier.bias\")\n",
    "print(nonfreeze_layers)\n",
    "# double-check\n",
    "# non_freeze_names = [name for name, param in model.named_parameters() if name in nonfreeze_layers]\n",
    "# print(non_freeze_names)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=args_lr)\n",
    "optimizer = AdamW([{'params':[param for name, param in model.named_parameters() if name in nonfreeze_layers]}], lr=args_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "hEqrLDMyPP-b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    betas: (0.9, 0.999)\n",
       "    correct_bias: True\n",
       "    eps: 1e-06\n",
       "    lr: 0.0001\n",
       "    weight_decay: 0.0\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0Zc4sscwIIM"
   },
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "vvP1jTBFKmd5"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=datasets[\"train\"],\n",
    "    eval_dataset=datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2070\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 6\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 696\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='696' max='696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [696/696 13:26, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693600</td>\n",
       "      <td>0.688572</td>\n",
       "      <td>0.560669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.692500</td>\n",
       "      <td>0.688282</td>\n",
       "      <td>0.594142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.679400</td>\n",
       "      <td>0.686858</td>\n",
       "      <td>0.564854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.643500</td>\n",
       "      <td>0.669616</td>\n",
       "      <td>0.610879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.578500</td>\n",
       "      <td>0.695661</td>\n",
       "      <td>0.573222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.724081</td>\n",
       "      <td>0.610879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.436700</td>\n",
       "      <td>0.803475</td>\n",
       "      <td>0.548117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.390200</td>\n",
       "      <td>0.816629</td>\n",
       "      <td>0.548117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 239\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to ziyan-595finalproj-finetuned-piqa/checkpoint-87\n",
      "Configuration saved in ziyan-595finalproj-finetuned-piqa/checkpoint-87/config.json\n",
      "Model weights saved in ziyan-595finalproj-finetuned-piqa/checkpoint-87/pytorch_model.bin\n",
      "tokenizer config file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-87/tokenizer_config.json\n",
      "Special tokens file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-87/special_tokens_map.json\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 239\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to ziyan-595finalproj-finetuned-piqa/checkpoint-174\n",
      "Configuration saved in ziyan-595finalproj-finetuned-piqa/checkpoint-174/config.json\n",
      "Model weights saved in ziyan-595finalproj-finetuned-piqa/checkpoint-174/pytorch_model.bin\n",
      "tokenizer config file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-174/tokenizer_config.json\n",
      "Special tokens file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-174/special_tokens_map.json\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 239\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to ziyan-595finalproj-finetuned-piqa/checkpoint-261\n",
      "Configuration saved in ziyan-595finalproj-finetuned-piqa/checkpoint-261/config.json\n",
      "Model weights saved in ziyan-595finalproj-finetuned-piqa/checkpoint-261/pytorch_model.bin\n",
      "tokenizer config file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-261/tokenizer_config.json\n",
      "Special tokens file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-261/special_tokens_map.json\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 239\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to ziyan-595finalproj-finetuned-piqa/checkpoint-348\n",
      "Configuration saved in ziyan-595finalproj-finetuned-piqa/checkpoint-348/config.json\n",
      "Model weights saved in ziyan-595finalproj-finetuned-piqa/checkpoint-348/pytorch_model.bin\n",
      "tokenizer config file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-348/tokenizer_config.json\n",
      "Special tokens file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-348/special_tokens_map.json\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 239\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to ziyan-595finalproj-finetuned-piqa/checkpoint-435\n",
      "Configuration saved in ziyan-595finalproj-finetuned-piqa/checkpoint-435/config.json\n",
      "Model weights saved in ziyan-595finalproj-finetuned-piqa/checkpoint-435/pytorch_model.bin\n",
      "tokenizer config file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-435/tokenizer_config.json\n",
      "Special tokens file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-435/special_tokens_map.json\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 239\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to ziyan-595finalproj-finetuned-piqa/checkpoint-522\n",
      "Configuration saved in ziyan-595finalproj-finetuned-piqa/checkpoint-522/config.json\n",
      "Model weights saved in ziyan-595finalproj-finetuned-piqa/checkpoint-522/pytorch_model.bin\n",
      "tokenizer config file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-522/tokenizer_config.json\n",
      "Special tokens file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-522/special_tokens_map.json\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 239\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to ziyan-595finalproj-finetuned-piqa/checkpoint-609\n",
      "Configuration saved in ziyan-595finalproj-finetuned-piqa/checkpoint-609/config.json\n",
      "Model weights saved in ziyan-595finalproj-finetuned-piqa/checkpoint-609/pytorch_model.bin\n",
      "tokenizer config file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-609/tokenizer_config.json\n",
      "Special tokens file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-609/special_tokens_map.json\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 239\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to ziyan-595finalproj-finetuned-piqa/checkpoint-696\n",
      "Configuration saved in ziyan-595finalproj-finetuned-piqa/checkpoint-696/config.json\n",
      "Model weights saved in ziyan-595finalproj-finetuned-piqa/checkpoint-696/pytorch_model.bin\n",
      "tokenizer config file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-696/tokenizer_config.json\n",
      "Special tokens file saved in ziyan-595finalproj-finetuned-piqa/checkpoint-696/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ziyan-595finalproj-finetuned-piqa/checkpoint-348 (score: 0.6696159839630127).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=696, training_loss=0.5766338973209776, metrics={'train_runtime': 818.0337, 'train_samples_per_second': 20.244, 'train_steps_per_second': 0.851, 'total_flos': 278804770958304.0, 'train_loss': 0.5766338973209776, 'epoch': 8.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory /home/ec2-user/SageMaker/test/saved_model/tune_3_layers/: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir /home/ec2-user/SageMaker/test/saved_model/tune_3_layers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/SageMaker/test/saved_model/tune_3_layers/\n",
      "Configuration saved in /home/ec2-user/SageMaker/test/saved_model/tune_3_layers/config.json\n",
      "Model weights saved in /home/ec2-user/SageMaker/test/saved_model/tune_3_layers/pytorch_model.bin\n",
      "tokenizer config file saved in /home/ec2-user/SageMaker/test/saved_model/tune_3_layers/tokenizer_config.json\n",
      "Special tokens file saved in /home/ec2-user/SageMaker/test/saved_model/tune_3_layers/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"/home/ec2-user/SageMaker/test/saved_model/tune_3_layers/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "n69oH5rcmxz3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: home/ec2-user/SageMaker/test/saved_model/tune_3_layers/ (stored 0%)\n",
      "  adding: home/ec2-user/SageMaker/test/saved_model/tune_3_layers/tokenizer_config.json (deflated 39%)\n",
      "  adding: home/ec2-user/SageMaker/test/saved_model/tune_3_layers/training_args.bin (deflated 48%)\n",
      "  adding: home/ec2-user/SageMaker/test/saved_model/tune_3_layers/special_tokens_map.json (deflated 40%)\n",
      "  adding: home/ec2-user/SageMaker/test/saved_model/tune_3_layers/vocab.txt (deflated 53%)\n",
      "  adding: home/ec2-user/SageMaker/test/saved_model/tune_3_layers/config.json (deflated 47%)\n",
      "  adding: home/ec2-user/SageMaker/test/saved_model/tune_3_layers/tokenizer.json (deflated 59%)\n",
      "  adding: home/ec2-user/SageMaker/test/saved_model/tune_3_layers/pytorch_model.bin (deflated 7%)\n",
      "  adding: home/ec2-user/SageMaker/test/saved_model/tune_3_layers/.ipynb_checkpoints/ (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r ziyan_tune_3_layers.zip '/home/ec2-user/SageMaker/test/saved_model/tune_3_layers/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "YIUvEc0R78Rr"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-44-a871fdc9ebee>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32massert\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORXJMZ5SBfwk"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTy8qy2KBl7O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1AkbLmd7r6A"
   },
   "source": [
    "## Test a sample"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "595finalproj_subtasktraining.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "041ac1dc8f264ae4ad820c6878370543": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2740236b038a48699ce4c846f418882f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43fb4455ec6c4c06a02fcea6547c8f2a",
      "placeholder": "",
      "style": "IPY_MODEL_9947462861c641788ff3d2551700057b",
      "value": "100%"
     }
    },
    "38d631cff84a4a2d8e48e814c761e0a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3b24287550a241998e51eda86281d8d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43fb4455ec6c4c06a02fcea6547c8f2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4dcb042033eb403b88031d83f2ea0ebe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58364149f49f401a995ed24de6438a57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cd91a4f0c914015ab1620d78066e095": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8088754586004f11a419a1aae4259a1f",
      "placeholder": "",
      "style": "IPY_MODEL_9b32b4bd88ce4a19ba37f95fd7f1a86f",
      "value": "100%"
     }
    },
    "609d03fca7dd4ca790ae2f66b8d61838": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "649c7a548b3644a8bbf7136a106bd793": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "659fec21dea14a858c0e66ac0a9d75ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6675e028e7cd41bd8c5860aa95dc3d41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b846573125fe410fb0ef91ca894df5e8",
      "placeholder": "",
      "style": "IPY_MODEL_4dcb042033eb403b88031d83f2ea0ebe",
      "value": " 1838/1838 [00:03&lt;00:00, 557.48it/s]"
     }
    },
    "7178653779c840a0af6bf381e9a9490e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7bb64338394409b92fd80c6847504a9",
      "max": 1838,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_38d631cff84a4a2d8e48e814c761e0a4",
      "value": 1838
     }
    },
    "783c0853a5a441398e88e1dd403737cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e38070d14810420c84492db589c6d1b3",
      "placeholder": "",
      "style": "IPY_MODEL_d2acd54e0007420fb24c34ea417a45ae",
      "value": "100%"
     }
    },
    "7d9412a705614e7f94446759302211b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8088754586004f11a419a1aae4259a1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8524420b862e4086a5ff2e825416f8ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_609d03fca7dd4ca790ae2f66b8d61838",
      "max": 16113,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_659fec21dea14a858c0e66ac0a9d75ea",
      "value": 16113
     }
    },
    "9947462861c641788ff3d2551700057b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b32b4bd88ce4a19ba37f95fd7f1a86f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c7dd103afd14cb183c71f675326f87c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9edc58dc09e14b9085e805614bde47fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a90b24c1fa5546cbb92866e5bf4b5a47",
      "placeholder": "",
      "style": "IPY_MODEL_9c7dd103afd14cb183c71f675326f87c",
      "value": " 16113/16113 [00:29&lt;00:00, 528.06it/s]"
     }
    },
    "a03fc9e623e643efb8b422880253ea32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_783c0853a5a441398e88e1dd403737cb",
       "IPY_MODEL_7178653779c840a0af6bf381e9a9490e",
       "IPY_MODEL_6675e028e7cd41bd8c5860aa95dc3d41"
      ],
      "layout": "IPY_MODEL_649c7a548b3644a8bbf7136a106bd793"
     }
    },
    "a1ee31b740924b7a9cfe72c4da86af71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58364149f49f401a995ed24de6438a57",
      "placeholder": "",
      "style": "IPY_MODEL_041ac1dc8f264ae4ad820c6878370543",
      "value": " 3084/3084 [00:05&lt;00:00, 555.14it/s]"
     }
    },
    "a51a995daec64a4084e927d41c925556": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2740236b038a48699ce4c846f418882f",
       "IPY_MODEL_8524420b862e4086a5ff2e825416f8ba",
       "IPY_MODEL_9edc58dc09e14b9085e805614bde47fa"
      ],
      "layout": "IPY_MODEL_7d9412a705614e7f94446759302211b5"
     }
    },
    "a90b24c1fa5546cbb92866e5bf4b5a47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b846573125fe410fb0ef91ca894df5e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2ed7d965e2644608187e003830f671b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b24287550a241998e51eda86281d8d4",
      "max": 3084,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_edf1c2873a234ea8814e353bf3bb01a8",
      "value": 3084
     }
    },
    "d2acd54e0007420fb24c34ea417a45ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e38070d14810420c84492db589c6d1b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edf1c2873a234ea8814e353bf3bb01a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f4ce30c803444e37a47cd8091adc9786": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5cd91a4f0c914015ab1620d78066e095",
       "IPY_MODEL_c2ed7d965e2644608187e003830f671b",
       "IPY_MODEL_a1ee31b740924b7a9cfe72c4da86af71"
      ],
      "layout": "IPY_MODEL_fc05ec7d7ff94eecbc560fe7d74f2a16"
     }
    },
    "f7bb64338394409b92fd80c6847504a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc05ec7d7ff94eecbc560fe7d74f2a16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}